{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6deb8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import datetime\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41fd0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "SEEDS = [1, 2, 3, 4, 5]\n",
    "MISSING_VALUE = -999999\n",
    "PARAMS = {'etas': [0.01, 0.05, 0.1, 0.2, 0.3], \n",
    "          'max_depths': [3, 4, 5],  \n",
    "          'subsamples':  [0.5,  0.8,  1.0],\n",
    "         'colsample_bytrees': [0.5,  0.8,  1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f215796",
   "metadata": {},
   "outputs": [],
   "source": [
    "VITAL_SIGN_COLS = ['Body_temperature', 'Pre_peripheral_O2_saturation',\n",
    "       'Post_peripheral_O2_saturation', 'Pre_pulse_rate', 'Post_pulse_rate',\n",
    "       'Pre_dyspnea', 'Post_dyspnea',]\n",
    "\n",
    "SYMPTOM_COLS = [ 'Fever', 'Cough', 'Runny_nose',\n",
    "       'Sore_throat', 'Smell', 'Diarrhea']\n",
    "\n",
    "DEMOGRAPHIC_COLS = ['age', 'gender', 'bmi']\n",
    "\n",
    "TIMES = ['morning', 'evening']\n",
    "\n",
    "LABEL_COLS = ['Admitted_within_1_day', 'Admitted_within_2_days', 'Admitted_within_3_days']\n",
    "\n",
    "vital_sign_feats = []\n",
    "symptom_feats = []\n",
    "\n",
    "\n",
    "for i in range(1, 4):\n",
    "    for time in TIMES:\n",
    "        for col in VITAL_SIGN_COLS:\n",
    "            vital_sign_feats.append(\"{}_day{}_{}\".format(col, i, time))\n",
    "            \n",
    "for i in range(1, 4):\n",
    "    for time in TIMES:\n",
    "        for col in SYMPTOM_COLS:\n",
    "            symptom_feats.append(\"{}_day{}_{}\".format(col, i, time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f20b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_one_hots = {'no': np.array([1, 0, 0, 0]), 'stay': np.array([0, 1, 0, 0]), 'up': np.array([0, 0, 1, 0]),\n",
    "               'down': np.array([0, 0, 0, 1]), np.nan: np.array([MISSING_VALUE, MISSING_VALUE, MISSING_VALUE, MISSING_VALUE])}\n",
    "\n",
    "gender_one_hots = {'male': np.array([1, 0, 0]), 'female': np.array([0, 1, 0]), \n",
    "                 'other': np.array([0, 0, 1]), np.nan: np.array([MISSING_VALUE, MISSING_VALUE, MISSING_VALUE])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23555a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_one_hot_features(features, one_hot_dict):\n",
    "    encoded_features = []\n",
    "    for feature in features:\n",
    "        tmp = []\n",
    "        for data in feature:\n",
    "            tmp.append(one_hot_dict[data])\n",
    "        tmp = np.concatenate(tmp)\n",
    "        encoded_features.append(tmp)\n",
    "    return np.array(encoded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d41c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prauc_score(label, pred):\n",
    "    precision, recall, threshold = precision_recall_curve(label, pred)\n",
    "    prauc = auc(recall, precision)\n",
    "    return prauc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a069a773",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90cc618",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_admitted_within_1_day_praucs = defaultdict(lambda: [])\n",
    "val_admitted_within_2_days_praucs = defaultdict(lambda: [])\n",
    "val_admitted_within_3_days_praucs = defaultdict(lambda: [])\n",
    "\n",
    "for seed in SEEDS:\n",
    "    train_df = pd.read_csv(PATH + 'training_SEED_{}.csv'.format(seed))\n",
    "    val_df = pd.read_csv(PATH + 'validation_SEED_{}.csv'.format(seed))\n",
    "    \n",
    "    \n",
    "    # Replace Nan with MISSING_VALUE (-999999)\n",
    "    train_df1 = train_df[vital_sign_feats + ['Age', 'BMI']].fillna(MISSING_VALUE)\n",
    "    train_df2 = train_df[symptom_feats]\n",
    "    train_df3 = train_df[['Gender']]\n",
    "    \n",
    "    # Replace Nan with MISSING_VALUE (-999999)\n",
    "    val_df1 = val_df[vital_sign_feats + ['Age', 'BMI']].fillna(MISSING_VALUE)\n",
    "    val_df2 = val_df[symptom_feats]\n",
    "    val_df3 = val_df[['Gender']]\n",
    "    \n",
    "    \n",
    "    train_feats1 = train_df1.values\n",
    "    train_feats2 = train_df2.values\n",
    "    train_feats3 = train_df3.values\n",
    "    \n",
    "    train_feats2 = encode_one_hot_features(train_feats2, symptom_one_hots)\n",
    "    train_feats3 = encode_one_hot_features(train_feats3, gender_one_hots)\n",
    "    \n",
    "    train_feats = np.concatenate([train_feats1, train_feats2, train_feats3], axis=1)  \n",
    "    train_labels = train_df[LABEL_COLS].values\n",
    "    \n",
    "    val_feats1 = val_df1.values\n",
    "    val_feats2 = val_df2.values\n",
    "    val_feats3 = val_df3.values\n",
    "    \n",
    "    val_feats2 = encode_one_hot_features(val_feats2, symptom_one_hots)\n",
    "    val_feats3 = encode_one_hot_features(val_feats3, gender_one_hots)\n",
    "    \n",
    "    val_feats = np.concatenate([val_feats1, val_feats2, val_feats3], axis=1)  \n",
    "    val_labels = val_df[LABEL_COLS].values\n",
    "    \n",
    "    \n",
    "    for eta in PARAMS['etas']:\n",
    "        for max_depth in PARAMS['max_depths']:\n",
    "            for subsample in PARAMS['subsamples']:\n",
    "                for colsample_bytree in PARAMS['colsample_bytrees']:\n",
    "                    admitted_within_1_day_model = XGBClassifier(colsample_bytree=colsample_bytree, learning_rate=eta, \n",
    "                                          max_depth=max_depth,subsample=subsample, missing=MISSING_VALUE, n_jobs=4)\n",
    "                    admitted_within_1_day_model.fit(train_feats, train_labels[:, 0])\n",
    "                    \n",
    "                    admitted_within_2_days_model = XGBClassifier(colsample_bytree=colsample_bytree, learning_rate=eta, \n",
    "                                          max_depth=max_depth,subsample=subsample, missing=MISSING_VALUE, n_jobs=4)\n",
    "                    admitted_within_2_days_model.fit(train_feats, train_labels[:, 1])\n",
    "                    \n",
    "                    admitted_within_3_days_model = XGBClassifier(colsample_bytree=colsample_bytree, learning_rate=eta, \n",
    "                                          max_depth=max_depth,subsample=subsample, missing=MISSING_VALUE, n_jobs=4)\n",
    "                    admitted_within_3_days_model.fit(train_feats, train_labels[:, 2])\n",
    "                    \n",
    "                    \n",
    "                    y_pred_admitted_within_1_day_val = admitted_within_1_day_model.predict_proba(val_feats)\n",
    "                    y_pred_admitted_within_2_days_val = admitted_within_2_days_model.predict_proba(val_feats)\n",
    "                    y_pred_admitted_within_3_days_val = admitted_within_3_days_model.predict_proba(val_feats)\n",
    "                    \n",
    "                    \n",
    "                    val_admitted_within_1_day_prauc = prauc_score(val_labels[:, 0], y_pred_admitted_within_1_day_val[:, 1])\n",
    "                    val_admitted_within_2_days_prauc = prauc_score(val_labels[:, 1], y_pred_admitted_within_2_days_val[:, 1])\n",
    "                    val_admitted_within_3_days_prauc = prauc_score(val_labels[:, 2], y_pred_admitted_within_3_days_val[:, 1])\n",
    "                    \n",
    "                    \n",
    "                    param = (eta, max_depth, subsample, colsample_bytree)\n",
    "                    \n",
    "                    val_admitted_within_1_day_praucs[param].append(val_admitted_within_1_day_prauc)\n",
    "                    val_admitted_within_2_days_praucs[param].append(val_admitted_within_2_days_prauc)\n",
    "                    val_admitted_within_3_days_praucs[param].append(val_admitted_within_3_days_prauc)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139369f5",
   "metadata": {},
   "source": [
    "## Select the best parameter based on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae1edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "admitted_within_1_day_best_param = ()\n",
    "admitted_within_1_day_best_val_prauc = 0\n",
    "admitted_within_2_days_best_param = ()\n",
    "admitted_within_2_days_best_val_prauc = 0\n",
    "admitted_within_3_days_best_param = ()\n",
    "admitted_within_3_days_best_val_prauc = 0\n",
    "\n",
    "for param in val_admitted_within_1_day_praucs:\n",
    "    if np.mean(val_admitted_within_1_day_praucs[param]) > admitted_within_1_day_best_val_prauc:\n",
    "        admitted_within_1_day_best_val_prauc = np.mean(val_admitted_within_1_day_praucs[param])\n",
    "        admitted_within_1_day_best_param = param\n",
    "    \n",
    "    if np.mean(val_admitted_within_2_days_praucs[param]) > admitted_within_2_days_best_val_prauc:\n",
    "        admitted_within_2_days_best_val_prauc = np.mean(val_admitted_within_2_days_praucs[param])\n",
    "        admitted_within_2_days_best_param = param\n",
    "        \n",
    "    if np.mean(val_admitted_within_3_days_praucs[param]) > admitted_within_3_days_best_val_prauc:\n",
    "        admitted_within_3_days_best_val_prauc = np.mean(val_admitted_within_3_days_praucs[param])\n",
    "        admitted_within_3_days_best_param = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598b448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta1, max_depth1, subsample1, colsample_bytree1 = admitted_within_1_day_best_param\n",
    "eta2, max_depth2, subsample2, colsample_bytree2 = admitted_within_2_days_best_param\n",
    "eta3, max_depth3, subsample3, colsample_bytree3 = admitted_within_3_days_best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95430bd7",
   "metadata": {},
   "source": [
    "## Evaluate on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe74253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admitted within 1 day PRAUC: 0.7700 +- 0.0693\n",
      "Admitted within 2 days PRAUC: 0.8359 +- 0.0372\n",
      "Admitted within 3 days PRAUC: 0.9451 +- 0.0185\n"
     ]
    }
   ],
   "source": [
    "test_admitted_within_1_day_praucs = []\n",
    "test_admitted_within_2_days_praucs = []\n",
    "test_admitted_within_3_days_praucs = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    train_df = pd.read_csv(PATH + 'training_SEED_{}.csv'.format(seed))\n",
    "    test_df = pd.read_csv(PATH + 'testing_SEED_{}.csv'.format(seed))\n",
    "    \n",
    "    # Replace Nan with MISSING_VALUE (-999999)\n",
    "    train_df1 = train_df[vital_sign_feats + ['Age', 'BMI']].fillna(MISSING_VALUE)\n",
    "    train_df2 = train_df[symptom_feats]\n",
    "    train_df3 = train_df[['Gender']]\n",
    "    \n",
    "    \n",
    "    # Replace Nan with MISSING_VALUE (-999999)\n",
    "    test_df1 = test_df[vital_sign_feats + ['Age', 'BMI']].fillna(MISSING_VALUE)\n",
    "    test_df2 = test_df[symptom_feats]\n",
    "    test_df3 = test_df[['Gender']]\n",
    "    \n",
    "    train_feats1 = train_df1.values\n",
    "    train_feats2 = train_df2.values\n",
    "    train_feats3 = train_df3.values\n",
    "    \n",
    "    train_feats2 = encode_one_hot_features(train_feats2, symptom_one_hots)\n",
    "    train_feats3 = encode_one_hot_features(train_feats3, gender_one_hots)\n",
    "    \n",
    "    train_feats = np.concatenate([train_feats1, train_feats2, train_feats3], axis=1)  \n",
    "    train_labels = train_df[LABEL_COLS].values\n",
    "    \n",
    "    test_feats1 = test_df1.values\n",
    "    test_feats2 = test_df2.values\n",
    "    test_feats3 = test_df3.values\n",
    "    \n",
    "    test_feats2 = encode_one_hot_features(test_feats2, symptom_one_hots)\n",
    "    test_feats3 = encode_one_hot_features(test_feats3, gender_one_hots)\n",
    "    \n",
    "    test_feats = np.concatenate([test_feats1, test_feats2, test_feats3], axis=1) \n",
    "    test_labels = test_df[LABEL_COLS].values\n",
    "    \n",
    "    \n",
    "    admitted_within_1_day_model = XGBClassifier(colsample_bytree=colsample_bytree1, learning_rate=eta1, \n",
    "                                          max_depth=max_depth1,subsample=subsample1, missing=MISSING_VALUE, n_jobs=4)\n",
    "    admitted_within_1_day_model.fit(train_feats, train_labels[:, 0])\n",
    "    \n",
    "    \n",
    "    admitted_within_2_days_model = XGBClassifier(colsample_bytree=colsample_bytree2, learning_rate=eta2, \n",
    "                                          max_depth=max_depth2,subsample=subsample2, missing=MISSING_VALUE, n_jobs=4)\n",
    "    admitted_within_2_days_model.fit(train_feats, train_labels[:, 1])\n",
    "    \n",
    "    \n",
    "    admitted_within_3_days_model = XGBClassifier(colsample_bytree=colsample_bytree3, learning_rate=eta3, \n",
    "                                          max_depth=max_depth3,subsample=subsample3, missing=MISSING_VALUE, n_jobs=4)\n",
    "    admitted_within_3_days_model.fit(train_feats, train_labels[:, 2])\n",
    "    \n",
    "    \n",
    "    y_pred_admitted_within_1_day_test = admitted_within_1_day_model.predict_proba(test_feats)\n",
    "    y_pred_admitted_within_2_days_test = admitted_within_2_days_model.predict_proba(test_feats)\n",
    "    y_pred_admitted_within_3_days_test = admitted_within_3_days_model.predict_proba(test_feats)\n",
    "    \n",
    "    test_admitted_within_1_day_prauc = prauc_score(test_labels[:, 0], y_pred_admitted_within_1_day_test[:, 1])\n",
    "    test_admitted_within_2_days_prauc = prauc_score(test_labels[:, 1], y_pred_admitted_within_2_days_test[:, 1])\n",
    "    test_admitted_within_3_days_prauc = prauc_score(test_labels[:, 2], y_pred_admitted_within_3_days_test[:, 1])\n",
    "    \n",
    "    \n",
    "    test_admitted_within_1_day_praucs.append(test_admitted_within_1_day_prauc)\n",
    "    test_admitted_within_2_days_praucs.append(test_admitted_within_2_days_prauc)\n",
    "    test_admitted_within_3_days_praucs.append(test_admitted_within_3_days_prauc)\n",
    "\n",
    "print('Admitted within 1 day PRAUC: {:.4f} +- {:.4f}'.format(np.mean(test_admitted_within_1_day_praucs), np.std(test_admitted_within_1_day_praucs)))\n",
    "print('Admitted within 2 days PRAUC: {:.4f} +- {:.4f}'.format(np.mean(test_admitted_within_2_days_praucs), np.std(test_admitted_within_2_days_praucs)))\n",
    "print('Admitted within 3 days PRAUC: {:.4f} +- {:.4f}'.format(np.mean(test_admitted_within_3_days_praucs), np.std(test_admitted_within_3_days_praucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a2952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbd0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55a6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b52e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c7983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
